# NDVI Analysis for Ethiopia Mar-Apr 2023

### Replicating similar analysis done for OND 2022
Similar analysis was done for the 2021 seasons which are described in the notebooks `01_eth_ndvi_ond2021.md` and `02_eth_ndvi_manyseas.md`
using the percent of median data found [here](https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/fews/web/africa/east/dekadal/emodis/ndvi_c6/percentofmedian/downloads/dekadal/).

Analysis for the JJAS 2022 season is in the file `04_eth_ndvi_jjas2022.md` from the same data source.

This notebook uses pentadal data from [here](https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/fews/web/africa/east/pentadal/eviirs/ndvi/percentofmean/downloads/pentadal/).




```python
%load_ext autoreload
%autoreload 2
%load_ext jupyter_black

from matplotlib.colors import ListedColormap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import geopandas as gpd
import os
import requests, zipfile, io, rasterio
from pathlib import Path
from rasterstats import zonal_stats

from datetime import date
import math
import glob
from dateutil.relativedelta import relativedelta
from src import constants
```

##### Importing required functions




```python
# from ochanticipy import CodAB
from src.constants import (
    ndvi_colors,
    ndvi_bins,
    ndvi_labels,
    country_config,
    pcode3_col,
    perc_bins,
    perc_labels,
    threshold,
    ndvi_exploration_dir,
)

from src.utils import (
    retrieve_raster_data,
    get_plot_dir,
    aggregate_admin,
    compute_dekads_below_thresh,
    plot_ndvi_aggr,
    load_livelihood_zones,
)
```


```python
input_dir = os.getenv("AA_DATA_DIR") + "/public/raw/glb/ndvi/pctmean/"
output_dir = os.getenv("AA_DATA_DIR") + "/public/exploration/eth/ndvi/"
```

##### Loading Admin Boundaries




```python
# load admin boundaries
# codab = CodAB(country_config=country_config)
# gdf_adm3 = codab.load(admin_level=3)
# pcode3_col = "ADM3_PCODE"
```

Adding these lines as on Windows, there may be a problem that was resolved earlier in the year on reading of zipped shapefiles which may not have been applied to the branch of the toolbox being used.




```python
filename3 = (
    "zip://"
    + os.getenv("AA_DATA_DIR")
    + "/public/raw/eth/cod_ab/eth_cod_ab.shp.zip/eth_admbnda_adm3_csa_bofedb_2021.shp"
)
gdf_adm3 = gpd.read_file(filename3)
```


```python
def plt_ndvi_dates(gdf_stats, data_col, colp_num=3, caption=None):
    num_plots = len(gdf_stats.date.unique())
    if num_plots == 1:
        colp_num = 1
    rows = math.ceil(num_plots / colp_num)
    position = range(1, num_plots + 1)
    fig = plt.figure(figsize=(10 * colp_num, 10 * rows))
    for i, d in enumerate(gdf_stats.date.unique()):
        ax = fig.add_subplot(rows, colp_num, i + 1)
        gdf_stats[gdf_stats.date == d].plot(
            ax=ax,
            column=data_col,
            legend=True,
            categorical=True,
            cmap=ListedColormap(constants.ndvi_colors),
        )
        ax.set_title(
            f"{pd.to_datetime(str(d)).strftime('%d-%m-%Y')} till "
            f"{(pd.to_datetime(str(d))+relativedelta(days=4)).strftime('%d-%m-%Y')}"
        )
        ax.axis("off")
    if caption:
        plt.figtext(0.7, 0.2, caption)
    plt.suptitle("Percent of mean NDVI", size=24, y=0.9)
    return fig


def clip_lz(gdf, lztype, pcode_col):
    gdf_lz_fn = load_livelihood_zones()
    # clip removes the admin3s that are not fully covered by (agro)pastoral livelihood zone
    gdf_clip = gpd.clip(gdf, gdf_lz_fn[gdf_lz_fn.LZTYPE.isin(lztype)])
    # determine admin3's that are (partially) (agro)pastoral
    gdf_clip["include"] = True
    gdf_include = gdf.merge(
        gdf_clip[[pcode_col, "include"]], on=pcode_col, how="left"
    )
    gdf_include["include"] = np.where(
        gdf_include.include.isnull(), False, True
    )
    gdf_include.loc[
        gdf_include.include == False,
        gdf_include.columns.str.startswith("perc_binned"),
    ] = np.nan
    return gdf_include
```

##### Getting raster data
The following section will take some time the first time it is run since it has to download the NDVI raster. Ensure the internet connection is stable during the initial download to reduce chances of IncompleteRead Errors. Once the download is done, the code reads the data and will not take so much time. 




```python
### If this section works, then the aggregate admin function should be okay.
# takes some time but when saving file,
# date is dropped which we need later
# should find a way to save with date in there
# raster_ma = retrieve_raster_data(
#    start_date=start_date,
#    end_date=end_date,
#    gdf=gdf_adm3,
# )
base_url = "https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/fews/web/africa/east/pentadal/eviirs/ndvi/percentofmean/downloads/pentadal/"
ma_pentads = list(range(13, 24 + 1))
ma_file = ["ea23" + str(pentad) + "pct.zip" for pentad in ma_pentads]
```


```python
for file in ma_file:
    r = requests.get(base_url + file)
    z = zipfile.ZipFile(io.BytesIO(r.content))
    z.extractall(input_dir)
```


```python
# list files that start with any value in ma_file
ma23_files = [f for f in glob.glob(os.path.join(input_dir, "ea23*.tif"))]
```


```python
# reading in files
woreda_stats_mean = pd.DataFrame()
woreda_stats_median = pd.DataFrame()
# using zonal stats as it can filter out no data values marked with 255.
for file in ma23_files:
    file_obj = rasterio.open(file)
    array = file_obj.read(1)
    summary_stats = zonal_stats(
        gdf_adm3,
        array,
        stats=["mean", "median"],
        nodata=255,
        all_touched=False,
        affine=file_obj.transform,
    )
    stats_df = pd.DataFrame(summary_stats)
    woreda_stats_mean["".join([n for n in file if n.isdigit()])] = stats_df[
        "mean"
    ]
    woreda_stats_median["".join([n for n in file if n.isdigit()])] = stats_df[
        "median"
    ]
```


```python
# converting from wide to long
raster_ma_mean = pd.concat(
    [gdf_adm3[["ADM3_PCODE", "geometry"]], woreda_stats_mean], axis=1
)
gdf_stats_adm3_mean = pd.melt(
    raster_ma_mean,
    id_vars=["ADM3_PCODE", "geometry"],
    var_name="period",
    value_name="mean",
)
gdf_stats_adm3_mean
```


```python
# converting from wide to long
raster_ma_median = pd.concat(
    [gdf_adm3[["ADM3_PCODE", "geometry"]], woreda_stats_median], axis=1
)
gdf_stats_adm3_median = pd.melt(
    raster_ma_median,
    id_vars=["ADM3_PCODE", "geometry"],
    var_name="period",
    value_name="median",
)
gdf_stats_adm3_median
```


```python
gdf_stats_adm3 = pd.merge(
    gdf_stats_adm3_mean,
    gdf_stats_adm3_median,
    on=["ADM3_PCODE", "geometry", "period"],
)
gdf_stats_adm3
```


```python
gdf_stats_adm3["year"] = 2023
gdf_stats_adm3["pentad"] = [a[-2:] for a in gdf_stats_adm3["period"]]
gdf_stats_adm3["modulo"] = pd.to_numeric(gdf_stats_adm3["pentad"]) % 6
gdf_stats_adm3["month"] = np.where(
    gdf_stats_adm3["modulo"] > 0,
    (pd.to_numeric(gdf_stats_adm3["pentad"]) // 6) + 1,
    pd.to_numeric(gdf_stats_adm3["pentad"]) // 6,
)
gdf_stats_adm3["day"] = np.where(
    gdf_stats_adm3["modulo"] == 1,
    1,
    np.where(
        gdf_stats_adm3["modulo"] == 2,
        6,
        np.where(
            gdf_stats_adm3["modulo"] == 3,
            11,
            np.where(
                gdf_stats_adm3["modulo"] == 4,
                16,
                np.where(gdf_stats_adm3["modulo"] == 5, 21, 26),
            ),
        ),
    ),
)
gdf_stats_adm3["date"] = [
    "%04d" % gdf_stats_adm3["year"][i]
    + "-"
    + "%02d" % gdf_stats_adm3["month"][i]
    + "-"
    + "%02d" % gdf_stats_adm3["day"][i]
    for i in range(0, len(gdf_stats_adm3["year"]))
]
gdf_stats_adm3
```


```python
gdf_stats_adm3["mean_below_80"] = gdf_stats_adm3["mean"] <= 80
gdf_stats_adm3.groupby(["mean_below_80", "month"])["mean_below_80"].count()
```


```python
gdf_stats_adm3["median_below_80"] = gdf_stats_adm3["median"] <= 80
gdf_stats_adm3.groupby(["median_below_80", "month"])["median_below_80"].count()
```


```python
gdf_stats_adm3["mean_binned"] = pd.cut(
    gdf_stats_adm3["mean"],
    ndvi_bins,
    labels=ndvi_labels,
)
gdf_stats_adm3["median_binned"] = pd.cut(
    gdf_stats_adm3["median"],
    ndvi_bins,
    labels=ndvi_labels,
)
gdf_stats_adm3
```


```python
(
    gdf_stats_adm3["mean_binned"] == gdf_stats_adm3["median_binned"]
).value_counts()
# they do not always fall in the same bin
```


```python
fig = plt_ndvi_dates(gdf_stats_adm3, "mean_binned", colp_num=6)
```


```python
fig = plt_ndvi_dates(gdf_stats_adm3, "median_binned", colp_num=6)
```


```python
fig = plt_ndvi_dates(gdf_stats_adm3, "median_binned", colp_num=4)
```


```python
gdf_medb_count_mean = compute_dekads_below_thresh(
    gdf_stats_adm3, pcode3_col, "mean", perc_bins, perc_labels, threshold=80
)
gdf_medb_count_median = compute_dekads_below_thresh(
    gdf_stats_adm3, pcode3_col, "median", perc_bins, perc_labels, threshold=80
)
gdf_medb_count = gdf_medb_count_mean.merge(
    gdf_medb_count_median,
    on=["ADM3_PCODE", "geometry"],
    suffixes=("_mean", "_median"),
)
gdf_medb_count
```


```python
(
    gdf_medb_count["perc_binned_mean"] == gdf_medb_count["perc_binned_median"]
).value_counts()
# they do not always fall in the same bin
# Roughly 3% of the time
```


```python
g = plot_ndvi_aggr(
    gdf_medb_count,
    feature_col="perc_binned_mean",
    title=f"Percentage of pentads Mar-Apr 2023 NDVI \n was <={threshold}% of mean NDVI aggregated by mean per woreda",
)
g = plot_ndvi_aggr(
    gdf_medb_count,
    feature_col="perc_binned_median",
    title=f"Percentage of pentads Mar-Apr 2023 NDVI \n was <={threshold}% of mean NDVI aggregated by median per woreda",
)
```


```python
gdf_lz_fn = load_livelihood_zones()
# quick plot of livelihood zones
g = gdf_lz_fn.plot("LZTYPE", legend=True)
g.axes.axis("off")
```


```python
gdf_stats_mask = clip_lz(
    gdf=gdf_medb_count,
    lztype=["Pastoral", "Agropastoral"],
    pcode_col=pcode3_col,
)
g = plot_ndvi_aggr(
    gdf_stats_mask,
    feature_col="perc_binned_mean",
    label_missing="non-pastoralist area",
    title=f"Percentage of pentads Mar-Apr 2023 NDVI \n was <={threshold}% of mean NDVI aggregated by mean per woreda",
)
g = plot_ndvi_aggr(
    gdf_stats_mask,
    feature_col="perc_binned_median",
    label_missing="non-pastoralist area",
    title=f"Percentage of pentads Mar-Apr 2023 NDVI \n was <={threshold}% of mean NDVI aggregated by median per woreda",
)
```


```python
gdf_stats_mask[gdf_stats_mask["perc_binned_median"] == "40-60"]
```


```python
gdf_adm3[gdf_adm3["ADM3_PCODE"] == "ET071304"]
```


```python
gdf_stats_mask[gdf_stats_mask["perc_binned_median"] == "20-40"]
```


```python
gdf_adm_sel = gdf_stats_mask[gdf_stats_mask["include"] == True]
(
    gdf_adm_sel["perc_binned_mean"] == gdf_adm_sel["perc_binned_median"]
).value_counts()
# this increases during the masking to ~10% mismatch.
```


```python
gdf_adm_sel["perc_binned_mean"].value_counts()
```


```python
gdf_adm_sel["perc_binned_median"].value_counts()
```


```python
gdf_stats_mask[
    [
        "ADM3_PCODE",
        "mean",
        "percent_mean",
        "perc_binned_mean",
        "median",
        "percent_median",
        "perc_binned_median",
        "include",
    ]
].to_csv(output_dir + "eth_ndvi_woreda_stats_ma2023.csv", index=False)
```


```python
gdf_stats_adm3[
    [
        "ADM3_PCODE",
        "period",
        "mean",
        "median",
        "year",
        "pentad",
        "date",
        "mean_binned",
        "median_binned",
    ]
].to_csv(output_dir + "eth_ndvi_mean_median_ma2023.csv", index=False)
```
